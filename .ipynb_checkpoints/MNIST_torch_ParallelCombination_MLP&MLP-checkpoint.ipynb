{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "labels = data['label'] \n",
    "features = data.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.from_numpy(features.values.reshape(-1,1,28,28))\n",
    "features = features.type(torch.float32)\n",
    "\n",
    "labels = torch.from_numpy(labels.values)\n",
    "labels = labels.type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_data = TensorDataset(features, labels)\n",
    "\n",
    "idx = list(range(len(train_data)))\n",
    "mid = int(0.9*len(train_data))\n",
    "\n",
    "# split and suffle indexes\n",
    "train_idx = SubsetRandomSampler(idx[:mid])\n",
    "test_idx = SubsetRandomSampler(idx[mid:])\n",
    "\n",
    "# data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=20, sampler=train_idx)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=20, sampler=test_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800\n",
      "4200\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader)*20)\n",
    "print(len(test_loader)*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_1(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class Net_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_1, self).__init__()        \n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)   \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "model_1 = Net_1()\n",
    "\n",
    "if train_on_gpu:\n",
    "    model_1.cuda()\n",
    "    \n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_2(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class Net_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_2, self).__init__()        \n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)   \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model_2 = Net_2()\n",
    "\n",
    "if train_on_gpu:\n",
    "    model_2.cuda()\n",
    "    \n",
    "print(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Model(Selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_3(\n",
      "  (fc1): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class Net_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_3, self).__init__()        \n",
    "        self.fc1 = nn.Linear(20,10)\n",
    "        self.fc2 = nn.Linear(10,10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)           \n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "model_3 = Net_3()\n",
    "\n",
    "if train_on_gpu:\n",
    "    model_3.cuda()\n",
    "    \n",
    "print(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion_1 = nn.CrossEntropyLoss()\n",
    "criterion_2 = nn.CrossEntropyLoss()\n",
    "criterion_3 = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer_1 = torch.optim.Adagrad(model_1.parameters(), lr=0.1)\n",
    "optimizer_2 = torch.optim.Adagrad(model_2.parameters(), lr=0.1)\n",
    "optimizer_3 = torch.optim.Adagrad(model_3.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss_1: 1.728619 \tTraining Loss_2: 0.790370 \tTraining Loss_3: 0.858299\n",
      "Epoch: 2 \tTraining Loss_1: 1.643722 \tTraining Loss_2: 0.779511 \tTraining Loss_3: 0.840399\n",
      "Epoch: 3 \tTraining Loss_1: 1.538113 \tTraining Loss_2: 0.769190 \tTraining Loss_3: 0.815331\n",
      "Epoch: 4 \tTraining Loss_1: 1.473631 \tTraining Loss_2: 0.753189 \tTraining Loss_3: 0.796022\n",
      "Epoch: 5 \tTraining Loss_1: 1.397166 \tTraining Loss_2: 0.754880 \tTraining Loss_3: 0.792981\n",
      "Epoch: 6 \tTraining Loss_1: 1.350845 \tTraining Loss_2: 0.740636 \tTraining Loss_3: 0.764003\n",
      "Epoch: 7 \tTraining Loss_1: 1.281630 \tTraining Loss_2: 0.718438 \tTraining Loss_3: 0.744955\n",
      "Epoch: 8 \tTraining Loss_1: 1.264511 \tTraining Loss_2: 0.716505 \tTraining Loss_3: 0.740776\n",
      "Epoch: 9 \tTraining Loss_1: 1.243565 \tTraining Loss_2: 0.708146 \tTraining Loss_3: 0.721750\n",
      "Epoch: 10 \tTraining Loss_1: 1.218782 \tTraining Loss_2: 0.703261 \tTraining Loss_3: 0.705842\n"
     ]
    }
   ],
   "source": [
    "# number of epochs \n",
    "epochs = 10\n",
    "\n",
    "model_1.train() \n",
    "model_2.train()\n",
    "model_3.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss_1 = 0.0\n",
    "    train_loss_2 = 0.0\n",
    "    train_loss_3 = 0.0\n",
    "    \n",
    "    total = 0.0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer_1.zero_grad()\n",
    "        optimizer_2.zero_grad()\n",
    "        optimizer_3.zero_grad()\n",
    "        \n",
    "        output_1 = model_1(data)\n",
    "        output_2 = model_2(data)\n",
    "        \n",
    "        output = torch.cat((output_1, output_2), 1)\n",
    "        #output = (output_1+output_2)/2\n",
    "        \n",
    "        output_3 = model_3(output)       \n",
    "        \n",
    "        loss_3 = criterion_3(output_3, target)\n",
    "        \n",
    "        \"\"\"\n",
    "        back_to_MLP1_MLP2 = output-loss_3*model_3.state_dict()['fc1.weight'].mean(0)\n",
    "        back_to_MLP1 = back_to_MLP1_MLP2[:,:10]\n",
    "        back_to_MLP2 = back_to_MLP1_MLP2[:,10:] \n",
    "        \"\"\"\n",
    "       \n",
    "        loss_2 = criterion_2(output_2, target)\n",
    "        loss_1 = criterion_1(output_1, target)\n",
    "        loss_3.backward(retain_graph=True)\n",
    "        loss_2.backward(retain_graph=True)\n",
    "        loss_1.backward()\n",
    "        \n",
    "        optimizer_1.step()\n",
    "        optimizer_2.step()\n",
    "        optimizer_3.step()\n",
    "        train_loss_1 += loss_1.item()*data.size(0)\n",
    "        train_loss_2 += loss_2.item()*data.size(0)\n",
    "        train_loss_3 += loss_3.item()*data.size(0)\n",
    "        \n",
    "        total += len(data) \n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss_1 = train_loss_1/total    \n",
    "    train_loss_2 = train_loss_2/total\n",
    "    train_loss_3 = train_loss_3/total\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss_1: {:.6f} \\tTraining Loss_2: {:.6f} \\tTraining Loss_3: {:.6f}'\\\n",
    "          .format(epoch+1,train_loss_1, train_loss_2, train_loss_3)) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss_1: 1.169330\tTest Loss_2: 0.548858\tTest Loss_3: 0.548858\n",
      "Test Accuracy_1: 57.76%\tTest Accuracy_2: 82.90%\tTest Accuracy_3: 83.76%\t (3518/4200.0)\n"
     ]
    }
   ],
   "source": [
    "correct_1 = 0.0\n",
    "correct_2 = 0.0\n",
    "correct_3 = 0.0\n",
    "test_loss_1 = 0.0\n",
    "test_loss_2 = 0.0\n",
    "test_loss_3 = 0.0\n",
    "total= 0.0\n",
    "\n",
    "model_1.eval()\n",
    "model_2.eval()\n",
    "model_3.eval()\n",
    "\n",
    "for data, target in test_loader:    \n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    output_1 = model_1(data)\n",
    "    output_2 = model_2(data)\n",
    "    output = torch.cat((output_1, output_2), 1)\n",
    "    #output = (output_1+output_2)/2\n",
    "    output_3 = model_3(output)        \n",
    "    loss_3 = criterion_3(output_3, target)\n",
    "    loss_2 = criterion_2(output_2, target)\n",
    "    loss_1 = criterion_1(output_1, target)\n",
    "    test_loss_1 += loss_1.item()*data.size(0)\n",
    "    test_loss_2 += loss_2.item()*data.size(0)\n",
    "    test_loss_3 += loss_3.item()*data.size(0)\n",
    "    _, pred_1 = torch.max(output_1, 1)\n",
    "    _, pred_2 = torch.max(output_2, 1)\n",
    "    _, pred_3 = torch.max(output_3, 1)\n",
    "    \n",
    "    correct_1 += np.squeeze(pred_1.eq(target.data.view_as(pred_1))).sum()\n",
    "    correct_2 += np.squeeze(pred_2.eq(target.data.view_as(pred_2))).sum()\n",
    "    correct_3 += np.squeeze(pred_3.eq(target.data.view_as(pred_3))).sum()\n",
    "    total += len(data)\n",
    "    \n",
    "# calculate and print average test loss\n",
    "test_loss_1 = test_loss_1/total\n",
    "test_loss_2 = test_loss_3/total\n",
    "test_loss_3 = test_loss_3/total\n",
    "print('Test Loss_1: {:.6f}\\tTest Loss_2: {:.6f}\\tTest Loss_3: {:.6f}'.format(test_loss_1,test_loss_2,test_loss_3)) \n",
    "\n",
    "# calculate and print accuracy\n",
    "print('Test Accuracy_1: {:.2f}%\\tTest Accuracy_2: {:.2f}%\\tTest Accuracy_3: {:.2f}%\\t ({}/{})' \\\n",
    "      .format(100. * np.float(correct_1) / total, 100. * np.float(correct_2) / total, 100. * np.float(correct_3) / total, correct_3, total))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data = torch.from_numpy(test_data.values.reshape(-1,1,28,28))\n",
    "test_data = test_data.type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.eval()\n",
    "model_2.eval()\n",
    "model_3.eval()\n",
    "\n",
    "result = []\n",
    "\n",
    "for data in test_data:    \n",
    "    if train_on_gpu:\n",
    "        data = data.cuda()\n",
    "    output_1 = model_1(data)\n",
    "    output_2 = model_2(data)\n",
    "    output = torch.cat((output_1, output_2), 1)\n",
    "    #output = (output_1+output_2)/2\n",
    "    output_3 = model_3(output)        \n",
    "    _, pred = torch.max(output_3, 1)\n",
    "    pred = pred.numpy()\n",
    "    result += pred.tolist()\n",
    "\n",
    "results = pd.Series(result,name=\"Label\")\n",
    "Imageld = pd.Series(range(1,len(result)+1),name=\"Imageld\")\n",
    "\n",
    "submission = pd.concat([Imageld,results],axis = 1)\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Imageld  Label\n",
      "0        1      2\n",
      "1        2      0\n",
      "2        3      7\n",
      "3        4      4\n",
      "4        5      8\n",
      "5        6      7\n",
      "6        7      0\n",
      "7        8      3\n",
      "8        9      0\n",
      "9       10      3\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('submission.csv')\n",
    "print(x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
