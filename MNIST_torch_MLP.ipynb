{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\nlabels = train_data['label'] \ntrain_data = train_data.drop('label', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\n\ndata = torch.from_numpy(train_data.values.reshape(-1,1,28,28))\ndata = data.type(torch.float32)\nlabels = torch.from_numpy(labels.values)\nlabels = labels.type(torch.long)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import datasets\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import TensorDataset\n\ntrain_data = TensorDataset(data, labels)\n\nidx = list(range(len(train_data)))\nmid = int(0.99*len(train_data))\n\n# split and suffle indexes\ntrain_idx = SubsetRandomSampler(idx[:mid])\ntest_idx = SubsetRandomSampler(idx[mid:])\n\n# data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=20, sampler=train_idx)\ntest_loader = torch.utils.data.DataLoader(train_data, batch_size=20, sampler=test_idx)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_loader)*20)\nprint(len(test_loader)*20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# define the NN architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()        \n        self.fc1 = nn.Linear(28 * 28, 512)\n        self.fc2 = nn.Linear(512, 512)\n        self.fc3 = nn.Linear(512, 10)\n        self.dropout = nn.Dropout(0.2)\n    def forward(self, x):\n        # flatten image input\n        x = x.view(-1, 28 * 28)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)   \n        x = F.log_softmax(self.fc3(x), dim=1)\n        return x\nmodel = Net()\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss function\ncriterion = nn.CrossEntropyLoss()\n\n# optimizer\noptimizer = torch.optim.Adagrad(model.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of epochs \nepochs = 85\n\nmodel.train() # prep model for training\n\nfor epoch in range(epochs):\n    \n    train_loss = 0.0\n    total = 0.0\n    \n    for data, target in train_loader:\n        optimizer.zero_grad()\n        output = model(data)        \n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()*data.size(0)\n        total += len(data) \n        \n    # print training statistics \n    # calculate average loss over an epoch\n    train_loss = train_loss/total\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1,train_loss))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0.0\ntest_loss = 0.0\ntotal= 0.0\n\nmodel.eval() # prep model for evaluation\n\nfor data, target in test_loader:\n    output = model(data)\n    loss = criterion(output, target)  \n    test_loss += loss.item()*data.size(0)\n    _, pred = torch.max(output, 1)\n    correct += np.squeeze(pred.eq(target.data.view_as(pred))).sum()\n    total += len(data)\n    \n# calculate and print average test loss\ntest_loss = test_loss/total\nprint('Test Loss: {:.6f}'.format(test_loss)) \n\n# calculate and print accuracy\nprint('Test Accuracy: {:.2f}% ({}/{})' .format(100. * np.float(correct) / total, \n                                           correct, total))\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/test.csv')\ntest_data = torch.from_numpy(test_data.values.reshape(-1,1,28,28))\ntest_data = test_data.type(torch.float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval() \nresult = []\n\nfor data in test_data:\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    _, pred = torch.max(output, 1)\n    pred = pred.numpy()\n    result += pred.tolist()\n\nresults = pd.Series(result,name=\"Label\")\nImageld = pd.Series(range(1,len(result)+1),name=\"Imageld\")\n\nsubmission = pd.concat([Imageld,results],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.read_csv('submission.csv')\nprint(x[:10])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}